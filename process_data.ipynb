{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data\n",
    "\n",
    "This notebook handles the processing of the dumps downloaded in ```download_wikis.ipynb```. The dumps downloaded are cleaned and combined into aggregated datasets. \n",
    "\n",
    "The data is then exploited to create data corresponding to the following main signals for an initial analysis.\n",
    "* Number of new registrations\n",
    "* Number of edits \n",
    "* Number of reverts and number of pages that were reverted\n",
    "* Revert rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_PATH = \"/dlabdata1/turkish_wiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMPS_PATH = '/dlabdata1/turkish_wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/dlabdata1/turkish_wiki'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names of the dumps were scraped from https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history_dumps. They are available in ```column_names.csv``` file in this directory. The csv file also contains the data types of the columns in the dumps that we use later to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = pd.read_csv('column_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Preprocess the data\n",
    "## 1) Combine the dumps of each year into one dataset\n",
    "The dumps of Turkish Wikipedia are separated into one dump per year. The function below concatanetes the data of the different dumps and returns them in one dataset. The data is then saved in ```/dlabdata1/turkish_wiki/aggregated.tsv.gz```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_yearly_dumps(column_names, dtypes, lang ='tr',  path=DUMPS_PATH, \n",
    "                         ending='tsv.bz2', years= list(range(2002, 2022))):\n",
    "    \"\"\"\n",
    "    Combines the yearly Wikipedia dumps into one aggregated DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        column_names : list\n",
    "            names of the columns of the dumps to be combined\n",
    "        dtypes : list\n",
    "            data types of the columns above, use str\n",
    "        lang : str\n",
    "            language of the dump, Default = 'tr'\n",
    "        path : str\n",
    "            location of the dumps, Default = DUMPS_PATH\n",
    "        ending : str\n",
    "            file extension of the dumps, Default = 'tsv.bz2'\n",
    "        years : list\n",
    "            years to be aggregated into one DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        df_lang: pd.DataFrame\n",
    "            combined DataFrame\n",
    "    \"\"\"\n",
    "    df_lang = pd.DataFrame()\n",
    "    for year in years:\n",
    "        start = time.time()\n",
    "        try:\n",
    "            df_lang = pd.concat([df_lang, pd.read_csv(f'{path}/{lang}-{year}.{ending}', sep='\\t', names=list(column_names), dtype=dtypes, warn_bad_lines=True, error_bad_lines=False)])\n",
    "            logging.warning(f'Loaded {lang}-{year} in {time.time() - start}')\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            logging.error(f'Error when processing {lang}-{year}')\n",
    "    return df_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = combine_yearly_dumps(column_names, dtypes=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f'{RES_PATH}').mkdir(parents=True, exist_ok=True)\n",
    "df_tr.to_csv(f'{RES_PATH}/aggregated.tsv.gz', index=False, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read the aggregated (raw) dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{RES_PATH}/aggregated.tsv.gz', sep=\"\\t\", dtype=str, error_bad_lines=False, warn_bad_lines=True, usecols= column_names.col_name[1:-1].values, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_entity</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>event_comment</th>\n",
       "      <th>event_user_id</th>\n",
       "      <th>event_user_text_historical</th>\n",
       "      <th>event_user_text</th>\n",
       "      <th>event_user_blocks_historical</th>\n",
       "      <th>event_user_blocks</th>\n",
       "      <th>event_user_groups_historical</th>\n",
       "      <th>...</th>\n",
       "      <th>revision_text_sha1</th>\n",
       "      <th>revision_content_model</th>\n",
       "      <th>revision_content_format</th>\n",
       "      <th>revision_is_deleted_by_page_deletion</th>\n",
       "      <th>revision_deleted_by_page_deletion_timestamp</th>\n",
       "      <th>revision_is_identity_reverted</th>\n",
       "      <th>revision_first_identity_reverting_revision_id</th>\n",
       "      <th>revision_seconds_to_identity_revert</th>\n",
       "      <th>revision_is_identity_revert</th>\n",
       "      <th>revision_is_from_before_page_creation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 22:51:28.0</td>\n",
       "      <td>(moved from tr.wikipedia.com)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.162.17.70</td>\n",
       "      <td>209.162.17.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8h2s3vbsvhk0xfyymbit06i0ef6j26s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 22:54:39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 22:54:39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Brion VIBBER</td>\n",
       "      <td>Brion VIBBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>jevuozi5divb9m74s5x4gr3xrr12ch4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true</td>\n",
       "      <td>2016-10-07 18:22:17.0</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 23:39:38.0</td>\n",
       "      <td>language links added - good luck, turkish wiki...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.128.44.46</td>\n",
       "      <td>80.128.44.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7s919m6k15itrhd1v3wwr8b1ci069on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-13 17:59:34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.140.196.133</td>\n",
       "      <td>193.140.196.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8sqxjw60e25kh1siv8e19jozs6tj52s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_entity event_type        event_timestamp  \\\n",
       "0     revision     create  2002-12-05 22:51:28.0   \n",
       "1         user     create  2002-12-05 22:54:39.0   \n",
       "2     revision     create  2002-12-05 22:54:39.0   \n",
       "3     revision     create  2002-12-05 23:39:38.0   \n",
       "4     revision     create  2002-12-13 17:59:34.0   \n",
       "\n",
       "                                       event_comment event_user_id  \\\n",
       "0                      (moved from tr.wikipedia.com)           NaN   \n",
       "1                                                NaN           NaN   \n",
       "2                                                NaN             1   \n",
       "3  language links added - good luck, turkish wiki...           NaN   \n",
       "4                                                NaN           NaN   \n",
       "\n",
       "  event_user_text_historical  event_user_text event_user_blocks_historical  \\\n",
       "0              209.162.17.70    209.162.17.70                          NaN   \n",
       "1                        NaN              NaN                          NaN   \n",
       "2               Brion VIBBER     Brion VIBBER                          NaN   \n",
       "3               80.128.44.46     80.128.44.46                          NaN   \n",
       "4            193.140.196.133  193.140.196.133                          NaN   \n",
       "\n",
       "  event_user_blocks event_user_groups_historical  ...  \\\n",
       "0               NaN                          NaN  ...   \n",
       "1               NaN                          NaN  ...   \n",
       "2               NaN                          NaN  ...   \n",
       "3               NaN                          NaN  ...   \n",
       "4               NaN                          NaN  ...   \n",
       "\n",
       "                revision_text_sha1 revision_content_model  \\\n",
       "0  8h2s3vbsvhk0xfyymbit06i0ef6j26s                    NaN   \n",
       "1                              NaN                    NaN   \n",
       "2  jevuozi5divb9m74s5x4gr3xrr12ch4                    NaN   \n",
       "3  7s919m6k15itrhd1v3wwr8b1ci069on                    NaN   \n",
       "4  8sqxjw60e25kh1siv8e19jozs6tj52s                    NaN   \n",
       "\n",
       "  revision_content_format revision_is_deleted_by_page_deletion  \\\n",
       "0                     NaN                                false   \n",
       "1                     NaN                                  NaN   \n",
       "2                     NaN                                 true   \n",
       "3                     NaN                                false   \n",
       "4                     NaN                                false   \n",
       "\n",
       "  revision_deleted_by_page_deletion_timestamp revision_is_identity_reverted  \\\n",
       "0                                         NaN                         false   \n",
       "1                                         NaN                           NaN   \n",
       "2                       2016-10-07 18:22:17.0                         false   \n",
       "3                                         NaN                         false   \n",
       "4                                         NaN                         false   \n",
       "\n",
       "  revision_first_identity_reverting_revision_id  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "  revision_seconds_to_identity_revert revision_is_identity_revert  \\\n",
       "0                                 NaN                       false   \n",
       "1                                 NaN                         NaN   \n",
       "2                                 NaN                       false   \n",
       "3                                 NaN                       false   \n",
       "4                                 NaN                       false   \n",
       "\n",
       "  revision_is_from_before_page_creation  \n",
       "0                                  true  \n",
       "1                                   NaN  \n",
       "2                                 false  \n",
       "3                                  true  \n",
       "4                                  true  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Clean and preprocess the data \n",
    "### a. Get column datatypes from scraped Wikipedia table.\n",
    "The datatypes of each of the columns are available in the scraped ```column_names``` DataFrame. We adapt the dump datatypes to corresponding Python datatypes to reduce the size of the dumps in memory and remove inconsistent rows from the dumps\n",
    "https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history_dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_type_to_dtype(col_name, data_type):\n",
    "    \"\"\"\n",
    "    Associates mediawiki datatypes to Python dtypes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        col_name : str\n",
    "            column name\n",
    "        data_type : str\n",
    "            mediawiki datatype\n",
    "    Returns \n",
    "    -------\n",
    "        dtype: str\n",
    "            corresponding python dtype\n",
    "    \"\"\"\n",
    "    \n",
    "    if (col_name == 'event_entity') or (col_name == 'event_type'):\n",
    "        return 'category'\n",
    "    elif ('timestamp' in col_name):\n",
    "        return 'datetime64[ns, UTC]'\n",
    "    elif (data_type == 'string') or (data_type == 'array<string>'):\n",
    "        return 'object'\n",
    "    elif (data_type == 'bigint') or (data_type == 'int') :\n",
    "        return 'Int64'\n",
    "    elif (data_type == 'boolean'):\n",
    "        return 'boolean'\n",
    "    else:\n",
    "        return 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_dtype = column_names[['col_name', 'data_type']].set_index('col_name').to_dict()['data_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_dtype = {k: transform_data_type_to_dtype(k, v) for k, v in col_to_dtype.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = list({k  for k, v in col_to_dtype.items() if v == 'category' })\n",
    "timestamp_cols = list({k  for k, v in col_to_dtype.items() if v == 'datetime64[ns, UTC]' })\n",
    "numerical_cols = list({k  for k, v in col_to_dtype.items() if v == 'Int64' })\n",
    "boolean_cols = list({k  for k, v in col_to_dtype.items() if v == 'boolean' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Preprocess the dataset to reduce size in memory\n",
    "The aggregated dataset is then transformed with the correct datatypes to ease future use. This preprocessing step also removes errors that appear in the dumps. For example errors that might appear in columns corresponding to timestamps (i.e. an IP address appears instead of a timestamp) are removed from the dataset. The transformation also reduces the size that the DataFrames occupy in memory since the conversions optimize the datatypes used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert low cardinality categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[category_cols] = df[category_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[timestamp_cols] = df[timestamp_cols].apply(pd.to_datetime, utc =True, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce').convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[boolean_cols] = df[boolean_cols].replace({'true': True,'false': False})\n",
    "df[boolean_cols] = df[boolean_cols].where(df[boolean_cols].applymap(type) == bool)\n",
    "df[boolean_cols] = df[boolean_cols].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned aggregated raw dump dataset\n",
    "df.to_csv(f'{RES_PATH}/cleaned_trwiki_1.tsv.gz', index=False, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Separate DataFrame for user, revision and page\n",
    "As it can be seen in the dumps documentation, some columns correspond only to events related to user, page or revisions. It is thus a good idea to separate the aggregated DataFrame into these three DataFrames to simplify further use.\n",
    "* ```user_df```: Has all events related to user activities. The events can correspond to the registering of a new account, changing the name of a user, changing the groups (rights) of a user or the blocking/unblocking of a user. Saved in ```/dlabdata1/turkish_wiki/user_events.tsv.gz```\n",
    "* ```page_df```: Has all events related to page activities. The events can correspond to the creation, deletion or merging of a page. Saved in ```/dlabdata1/turkish_wiki/page_events.tsv.gz```\n",
    "* ```revision_df```: Has all events related to revisions (edits). Saved in ```/dlabdata1/turkish_wiki/revision_events.tsv.gz```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = df[df['event_entity'] == 'user'][['event_entity', 'event_type', 'event_timestamp', 'event_comment',\n",
    "       'event_user_id', 'event_user_text_historical', 'event_user_text',\n",
    "       'event_user_blocks_historical', 'event_user_blocks',\n",
    "       'event_user_groups_historical', 'event_user_groups',\n",
    "       'event_user_is_bot_by_historical', 'event_user_is_bot_by',\n",
    "       'event_user_is_created_by_self', 'event_user_is_created_by_system',\n",
    "       'event_user_is_created_by_peer', 'event_user_is_anonymous',\n",
    "       'event_user_registration_timestamp', 'event_user_creation_timestamp',\n",
    "       'event_user_first_edit_timestamp', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision',\n",
    "       'user_id', 'user_text_historical', 'user_text',\n",
    "       'user_blocks_historical', 'user_blocks', 'user_groups_historical',\n",
    "       'user_groups', 'user_is_bot_by_historical', 'user_is_bot_by',\n",
    "       'user_is_created_by_self', 'user_is_created_by_system',\n",
    "       'user_is_created_by_peer', 'user_is_anonymous',\n",
    "       'user_registration_timestamp', 'user_creation_timestamp',\n",
    "       'user_first_edit_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.to_csv(f'{RES_PATH}/user_events.tsv.gz', index=False, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df = df[df['event_entity'] == 'page'][['event_entity', 'event_type', 'event_timestamp', 'event_comment',\n",
    "       'event_user_id', 'event_user_text_historical', 'event_user_text',\n",
    "       'event_user_blocks_historical', 'event_user_blocks',\n",
    "       'event_user_groups_historical', 'event_user_groups',\n",
    "       'event_user_is_bot_by_historical', 'event_user_is_bot_by',\n",
    "       'event_user_is_created_by_self', 'event_user_is_created_by_system',\n",
    "       'event_user_is_created_by_peer', 'event_user_is_anonymous',\n",
    "       'event_user_registration_timestamp', 'event_user_creation_timestamp',\n",
    "       'event_user_first_edit_timestamp', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id',\n",
    "       'page_title_historical', 'page_title', 'page_namespace_historical',\n",
    "       'page_namespace_is_content_historical', 'page_namespace',\n",
    "       'page_namespace_is_content', 'page_is_redirect', 'page_is_deleted',\n",
    "       'page_creation_timestamp', 'page_first_edit_timestamp',\n",
    "       'page_revision_count', 'page_seconds_since_previous_revision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df.to_csv(f'{RES_PATH}/page_events.tsv.gz', index=False, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df = df[df['event_entity'] == 'revision'][['event_entity', 'event_type', 'event_timestamp', 'event_comment',\n",
    "       'event_user_id', 'event_user_text_historical', 'event_user_text',\n",
    "       'event_user_blocks_historical', 'event_user_blocks',\n",
    "       'event_user_groups_historical', 'event_user_groups',\n",
    "       'event_user_is_bot_by_historical', 'event_user_is_bot_by',\n",
    "       'event_user_is_created_by_self', 'event_user_is_created_by_system',\n",
    "       'event_user_is_created_by_peer', 'event_user_is_anonymous',\n",
    "       'event_user_registration_timestamp', 'event_user_creation_timestamp',\n",
    "       'event_user_first_edit_timestamp', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id',\n",
    "       'page_title_historical', 'page_title', 'page_namespace_historical',\n",
    "       'page_namespace_is_content_historical', 'page_namespace',\n",
    "       'page_namespace_is_content', 'page_is_redirect', 'page_is_deleted',\n",
    "       'page_creation_timestamp', 'page_first_edit_timestamp',\n",
    "       'page_revision_count', 'page_seconds_since_previous_revision',\n",
    "       'revision_id', 'revision_parent_id',\n",
    "       'revision_minor_edit', 'revision_deleted_parts',\n",
    "       'revision_deleted_parts_are_suppressed', 'revision_text_bytes',\n",
    "       'revision_text_bytes_diff', 'revision_text_sha1',\n",
    "       'revision_content_model', 'revision_content_format',\n",
    "       'revision_is_deleted_by_page_deletion',\n",
    "       'revision_deleted_by_page_deletion_timestamp',\n",
    "       'revision_is_identity_reverted',\n",
    "       'revision_first_identity_reverting_revision_id',\n",
    "       'revision_seconds_to_identity_revert', 'revision_is_identity_revert',\n",
    "       'revision_is_from_before_page_creation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df.to_csv(f'{RES_PATH}/revision_events.tsv.gz', index=False, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Get main signals\n",
    "In this part we retrieve the main signals mentioned above from the dumps.\n",
    "## 1) Newcomers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all user creation events\n",
    "\n",
    "Processes the data and returns a DataFrame called ```all_registrations``` where all registration events to Turkish Wikipedia are available. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/all_registrations.csv```\n",
    "\n",
    "The format of the DataFrame is as such:\n",
    " * date : Timestamp of the registration event\n",
    " * user_id : ID of the registered user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(f'{RES_PATH}/user_events.tsv.gz', sep=\"\\t\", error_bad_lines=False, warn_bad_lines=True, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    # Convert data types\n",
    "    user_df = user_df.convert_dtypes()\n",
    "    \n",
    "    # Process dates\n",
    "    user_timestamp_columns = [col for col in user_df.columns if 'timestamp' in col]\n",
    "    user_df[user_timestamp_columns] = user_df[user_timestamp_columns].apply(pd.to_datetime, utc =True, errors='coerce')\n",
    "    user_df[\"date\"] = user_df.event_timestamp.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # User registration event\n",
    "    create_event_mask = (user_df.event_entity == 'user') & (user_df.event_type == 'create')\n",
    "    # Filter bots\n",
    "    no_bot_mask = (user_df['event_user_is_bot_by'].isna() | user_df['event_user_is_bot_by_historical'].isna())\n",
    "    # Additional Filters\n",
    "    self_creation_mask = (user_df['event_user_is_created_by_self'] == True)\n",
    "    no_anon_mask = (user_df['event_user_is_anonymous'] != True)\n",
    "\n",
    "    \n",
    "    all_registrations = user_df[create_event_mask & no_anon_mask & no_bot_mask & self_creation_mask][['event_timestamp', 'event_user_id']]\n",
    "    all_registrations.columns = ['date', 'user_id']\n",
    "    all_registrations.to_csv(f'{DATA_PATH}/processed_data/all_registrations.csv', index =False)\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2005-09-08 00:14:22+00:00</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2005-09-08 00:38:01+00:00</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2005-09-08 06:48:49+00:00</td>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2005-09-08 08:37:43+00:00</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2005-09-08 09:07:11+00:00</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date  user_id\n",
       "762 2005-09-08 00:14:22+00:00     2985\n",
       "763 2005-09-08 00:38:01+00:00     2986\n",
       "764 2005-09-08 06:48:49+00:00     2987\n",
       "765 2005-09-08 08:37:43+00:00     2988\n",
       "766 2005-09-08 09:07:11+00:00     2989"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_registrations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily number of registrations\n",
    "\n",
    "Processes the data and returns a DataFrame called ```group_creation``` where daily number of registrations to Turkish Wikipedia are available. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/newcomers.csv```\n",
    "\n",
    "The format of the DataFrame is as such:\n",
    " * date : Timestamp of the day\n",
    " * number_of_newcomers : Number of registrations that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    # Convert data types\n",
    "    user_df = user_df.convert_dtypes()\n",
    "\n",
    "    # Process dates\n",
    "    user_timestamp_columns = [col for col in user_df.columns if 'timestamp' in col]\n",
    "    user_df[user_timestamp_columns] = user_df[user_timestamp_columns].apply(pd.to_datetime, utc =True, errors='coerce')\n",
    "    user_df[\"date\"] = user_df.event_timestamp.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # User registration event\n",
    "    create_event_mask = (user_df.event_entity == 'user') & (user_df.event_type == 'create')\n",
    "    # Filter bots\n",
    "    no_bot_mask = (user_df['event_user_is_bot_by'].isna() | user_df['event_user_is_bot_by_historical'].isna())\n",
    "    # Additional Filters\n",
    "    self_creation_mask = (user_df['event_user_is_created_by_self'] == True)\n",
    "    no_anon_mask = (user_df['event_user_is_anonymous'] != True)\n",
    "\n",
    "    # Group registrations by calendar day and get number of registrations\n",
    "    group_creation = user_df[create_event_mask & no_anon_mask & no_bot_mask & self_creation_mask].groupby(['date'])['event_user_id'].size()\n",
    "\n",
    "    # Format the data\n",
    "    group_creation = group_creation.reset_index()\n",
    "    group_creation.columns = ['date', 'number_of_newcomers']\n",
    "    group_creation['date'] = pd.to_datetime(group_creation['date'],   utc = True)\n",
    "    group_creation.to_csv(f'{DATA_PATH}/processed_data/newcomers.csv', index =False)\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>number_of_newcomers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-09-08 00:00:00+00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-09-09 00:00:00+00:00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-09-10 00:00:00+00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-09-11 00:00:00+00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-09-12 00:00:00+00:00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  number_of_newcomers\n",
       "0 2005-09-08 00:00:00+00:00                   22\n",
       "1 2005-09-09 00:00:00+00:00                   16\n",
       "2 2005-09-10 00:00:00+00:00                   12\n",
       "3 2005-09-11 00:00:00+00:00                   13\n",
       "4 2005-09-12 00:00:00+00:00                   19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_creation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df = pd.read_csv(f'{RES_PATH}/revision_events.tsv.gz', sep=\"\\t\", usecols= ['event_type', 'page_namespace',  'event_entity', 'event_type', 'event_timestamp', \n",
    "       'event_user_id', 'event_user_groups', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id', \n",
    "       'event_user_id', 'event_user_is_bot_by',\n",
    "       'page_title', 'page_revision_count', 'revision_minor_edit',\n",
    "       'revision_text_bytes', 'revision_text_bytes_diff','revision_is_identity_revert',\n",
    "       'revision_is_identity_revert', 'revision_is_identity_reverted'],  error_bad_lines=False, warn_bad_lines=True, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_entity</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>event_user_id</th>\n",
       "      <th>event_user_groups</th>\n",
       "      <th>event_user_is_bot_by</th>\n",
       "      <th>event_user_revision_count</th>\n",
       "      <th>event_user_seconds_since_previous_revision</th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_namespace</th>\n",
       "      <th>page_revision_count</th>\n",
       "      <th>revision_minor_edit</th>\n",
       "      <th>revision_text_bytes</th>\n",
       "      <th>revision_text_bytes_diff</th>\n",
       "      <th>revision_is_identity_reverted</th>\n",
       "      <th>revision_is_identity_revert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 22:51:28+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2740662.0</td>\n",
       "      <td>Anasayfa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>809.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 22:54:39+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Main_Page</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-05 23:39:38+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2740662.0</td>\n",
       "      <td>Anasayfa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-13 17:59:34+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2740662.0</td>\n",
       "      <td>Anasayfa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>890.0</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revision</td>\n",
       "      <td>create</td>\n",
       "      <td>2002-12-13 18:01:20+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2740662.0</td>\n",
       "      <td>Anasayfa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_entity event_type            event_timestamp  event_user_id  \\\n",
       "0     revision     create  2002-12-05 22:51:28+00:00            NaN   \n",
       "1     revision     create  2002-12-05 22:54:39+00:00            1.0   \n",
       "2     revision     create  2002-12-05 23:39:38+00:00            NaN   \n",
       "3     revision     create  2002-12-13 17:59:34+00:00            NaN   \n",
       "4     revision     create  2002-12-13 18:01:20+00:00            NaN   \n",
       "\n",
       "  event_user_groups event_user_is_bot_by  event_user_revision_count  \\\n",
       "0               NaN                  NaN                        NaN   \n",
       "1               NaN                  NaN                        1.0   \n",
       "2               NaN                  NaN                        NaN   \n",
       "3               NaN                  NaN                        NaN   \n",
       "4               NaN                  NaN                        NaN   \n",
       "\n",
       "   event_user_seconds_since_previous_revision    page_id page_title  \\\n",
       "0                                         NaN  2740662.0   Anasayfa   \n",
       "1                                         NaN        5.0  Main_Page   \n",
       "2                                         NaN  2740662.0   Anasayfa   \n",
       "3                                         NaN  2740662.0   Anasayfa   \n",
       "4                                         NaN  2740662.0   Anasayfa   \n",
       "\n",
       "   page_namespace  page_revision_count  revision_minor_edit  \\\n",
       "0             0.0                  1.0                 True   \n",
       "1             0.0                  1.0                False   \n",
       "2             0.0                  2.0                False   \n",
       "3             0.0                  3.0                False   \n",
       "4             0.0                  4.0                False   \n",
       "\n",
       "   revision_text_bytes  revision_text_bytes_diff  \\\n",
       "0                809.0                     809.0   \n",
       "1                 24.0                      24.0   \n",
       "2               1010.0                     201.0   \n",
       "3                890.0                    -120.0   \n",
       "4                891.0                       1.0   \n",
       "\n",
       "   revision_is_identity_reverted  revision_is_identity_revert  \n",
       "0                          False                        False  \n",
       "1                          False                        False  \n",
       "2                          False                        False  \n",
       "3                          False                        False  \n",
       "4                          False                        False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of edits per day, user kind and page id\n",
    "\n",
    "Processes the data and returns a DataFrame called ```dict_edits_byid```. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/edits.csv```\n",
    "\n",
    "The format of the DataFrame is as such:\n",
    " * date : Timestamp of the day\n",
    " * page_id : ID of the edited page\n",
    " * user_kind : User kind: account, anonymous or bot \n",
    " * event_user_id : Number of edits\n",
    " * revision_text_bytes : Total edited bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    # Data type conversion\n",
    "    revision_df = revision_df.convert_dtypes()\n",
    "\n",
    "    # Choose revisions\n",
    "    create_revision_mask = (revision_df.event_entity=='revision') & (revision_df.event_type == 'create')\n",
    "    # Namespace 0 selects edits to articles\n",
    "    ns_mask = revision_df.page_namespace == 0\n",
    "    \n",
    "    revision_df = revision_df[create_revision_mask & ns_mask]\n",
    "\n",
    "    revision_df['revision_text_bytes'] = pd.to_numeric(revision_df['revision_text_bytes'], errors='coerce').fillna(0)\n",
    "    revision_df['event_timestamp'] = pd.to_datetime(revision_df['event_timestamp'],  utc = True, errors = 'coerce')\n",
    "    \n",
    "    revision_df[\"date\"] = revision_df.event_timestamp.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get user kinds\n",
    "    revision_df['user_kind'] = revision_df.apply(lambda row: 'anonymous' if pd.isna(row.event_user_id) else 'bot' if not pd.isna(row.event_user_is_bot_by) else 'account', axis=1)\n",
    "\n",
    "    # group by date, page_id, user_kind\n",
    "\n",
    "    dict_edits_byid = revision_df.groupby(['date', 'page_id', 'user_kind']).agg(\n",
    "        {'event_user_id': 'size', 'revision_text_bytes': 'sum'})\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edits_byid.to_csv(f'{DATA_PATH}/processed_data/edits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily number of edits by user_kind\n",
    "\n",
    "Processes the data and returns a DataFrame called ```daily_edits```. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/daily_edits.csv```\n",
    "\n",
    "The format of the DataFrame is as such:\n",
    " * date : Timestamp of the day\n",
    " * user_kind : User kind: account, anonymous or bot \n",
    " * event_user_id : Number of edits\n",
    " * revision_text_bytes : Total edited bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    dict_edits_byid = pd.read_csv(f'{DATA_PATH}/processed_data/edits.csv')\n",
    "    daily_edits = dict_edits_byid.groupby(['date', 'user_kind']).agg({'event_user_id': 'sum', 'revision_text_bytes': 'sum'})\n",
    "    daily_edits = daily_edits.reset_index()\n",
    "    daily_edits['date'] = pd.to_datetime(daily_edits['date'],   utc = True)\n",
    "    daily_edits.columns = ['date', 'user_kind', 'number_of_edits', 'total_edited_bytes']\n",
    "    daily_edits.to_csv(f'{DATA_PATH}/processed_data/daily_edits.csv')\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_kind</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>total_edited_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-12-05 00:00:00+00:00</td>\n",
       "      <td>account</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-12-05 00:00:00+00:00</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-12-13 00:00:00+00:00</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>2</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-12-16 00:00:00+00:00</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>2</td>\n",
       "      <td>4766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-12-17 00:00:00+00:00</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>1</td>\n",
       "      <td>4310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  user_kind  number_of_edits  total_edited_bytes\n",
       "0 2002-12-05 00:00:00+00:00    account                1                  24\n",
       "1 2002-12-05 00:00:00+00:00  anonymous                2                1819\n",
       "2 2002-12-13 00:00:00+00:00  anonymous                2                1781\n",
       "3 2002-12-16 00:00:00+00:00  anonymous                2                4766\n",
       "4 2002-12-17 00:00:00+00:00  anonymous                1                4310"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_edits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw edits coming from registered accounts\n",
    "\n",
    "Processes the data and returns a DataFrame called ```revision_df``` containing raw edit data of edits from registered accounts. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/account_edits.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    revision_df = pd.read_csv(f'{RES_PATH}/revision_events.tsv.gz', sep=\"\\t\", usecols= ['event_type', 'page_namespace',  'event_entity', 'event_type', 'event_timestamp', \n",
    "       'event_user_id', 'event_user_groups', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id', \n",
    "       'event_user_id', 'event_user_is_bot_by',\n",
    "       'page_title', 'page_revision_count', 'revision_minor_edit',\n",
    "       'revision_text_bytes', 'revision_text_bytes_diff','revision_is_identity_revert',\n",
    "       'revision_is_identity_revert', 'revision_is_identity_reverted'], error_bad_lines=False, warn_bad_lines=True, compression = 'gzip')\n",
    "    \n",
    "    revision_df = revision_df.convert_dtypes()\n",
    "\n",
    "    create_revision_mask = (revision_df.event_entity=='revision') & (revision_df.event_type == 'create')\n",
    "    ns_mask = revision_df.page_namespace == 0\n",
    "    \n",
    "    account_mask = (~revision_df.event_user_id.isna()) & (revision_df.event_user_is_bot_by.isna())\n",
    "    \n",
    "    revision_df = revision_df[create_revision_mask & ns_mask & account_mask]\n",
    "\n",
    "    revision_df['revision_text_bytes'] = pd.to_numeric(revision_df['revision_text_bytes'], errors='coerce').fillna(0)\n",
    "    revision_df['event_timestamp'] = pd.to_datetime(revision_df['event_timestamp'],  utc = True, errors = 'coerce')\n",
    "    \n",
    "    revision_df = revision_df[['event_type', 'event_timestamp', \n",
    "       'event_user_id', 'event_user_groups', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id', \n",
    "       'event_user_id', 'event_user_is_bot_by',\n",
    "       'page_title', 'page_revision_count', 'revision_minor_edit',\n",
    "       'revision_text_bytes', 'revision_text_bytes_diff','revision_is_identity_revert']]\n",
    "    \n",
    "    \n",
    "    revision_df.to_csv(f'{DATA_PATH}/processed_data/account_edits.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw registerations with only the relevant columns\n",
    "\n",
    "Processes the data and returns a DataFrame called ```revision_df``` where all raw edit information is stored. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/all_edits.csv```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    revision_df = pd.read_csv(f'{RES_PATH}/revision_events.tsv.gz', sep=\"\\t\", usecols= ['event_type', 'page_namespace',  'event_entity', 'event_type', 'event_timestamp', \n",
    "       'event_user_id', 'event_user_groups', 'event_user_revision_count',\n",
    "       'event_user_seconds_since_previous_revision', 'page_id', \n",
    "       'event_user_id', 'event_user_is_bot_by', 'event_user_text_historical', \n",
    "       'page_title', 'page_revision_count', 'revision_minor_edit',\n",
    "       'revision_text_bytes', 'revision_text_bytes_diff','revision_is_identity_revert',\n",
    "       'revision_is_identity_revert', 'revision_is_identity_reverted'], error_bad_lines=False, warn_bad_lines=True, compression = 'gzip')\n",
    "    \n",
    "    \n",
    "    revision_df = revision_df.convert_dtypes()\n",
    "\n",
    "    create_revision_mask = (revision_df.event_entity=='revision') & (revision_df.event_type == 'create')\n",
    "    ns_mask = revision_df.page_namespace == 0\n",
    "    \n",
    "    \n",
    "    revision_df = revision_df[create_revision_mask & ns_mask]\n",
    "\n",
    "    revision_df['event_timestamp'] = pd.to_datetime(revision_df['event_timestamp'],  utc = True, errors = 'coerce')\n",
    "    \n",
    "    revision_df = revision_df[['event_type', 'event_timestamp', \n",
    "       'event_user_id', 'event_user_text_historical', 'page_id', 'revision_minor_edit',\n",
    "       'revision_is_identity_revert', 'revision_is_identity_reverted']]\n",
    "    \n",
    "    revision_df.to_csv(f'{DATA_PATH}/processed_data/all_edits.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Reverts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df = pd.read_csv(f'{RES_PATH}/revision_events.tsv.gz', sep=\"\\t\", usecols= ['event_type', 'page_namespace',  'event_entity', 'event_type', 'event_timestamp', \n",
    "   'event_user_id', 'event_user_groups', 'event_user_revision_count',\n",
    "   'event_user_seconds_since_previous_revision', 'page_id', \n",
    "   'event_user_id', 'event_user_is_bot_by', 'event_user_text_historical', \n",
    "   'page_title', 'page_revision_count', 'revision_minor_edit',\n",
    "   'revision_text_bytes', 'revision_text_bytes_diff','revision_is_identity_revert',\n",
    "   'revision_is_identity_revert', 'revision_is_identity_reverted'], error_bad_lines=False, warn_bad_lines=True, compression = 'gzip')\n",
    "\n",
    "revision_df['event_timestamp'] = pd.to_datetime(revision_df['event_timestamp'],  utc = True, errors = 'coerce')\n",
    "    \n",
    "revision_df[\"date\"] = revision_df.event_timestamp.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Get user kinds\n",
    "revision_df['user_kind'] = revision_df.apply(lambda row: 'anonymous' if pd.isna(row.event_user_id) else 'bot' if not pd.isna(row.event_user_is_bot_by) else 'account', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily number of reverted edits or revert edits\n",
    "\n",
    "Processes the data and returns DataFrames called ```df_reverted```  and ```df_reverts```. ```df_reverted``` corresponds to all edits that were reverted later on, and ```df_reverts``` corresponds to all edits that are reverts. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/...```,\n",
    "\n",
    "The format of the DataFrames is as such:\n",
    " * date : Timestamp of the day\n",
    " * user_kind : User kind\n",
    " * revision_is_identity_reverted/revision_is_identity_revert: Number of registrations that were reverted later or that were reverts on the corresponding day by the corresponding user_kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    #get reverts per day as well as reverted\n",
    "    df_reverted = revision_df[revision_df['revision_is_identity_reverted'] == True].groupby(['date', 'user_kind'])['revision_is_identity_reverted'].size()\n",
    "    df_reverts = revision_df[revision_df['revision_is_identity_revert'] == True].groupby(['date', 'user_kind'])['revision_is_identity_revert'].size()\n",
    "\n",
    "    # reindex so all dates are filled\n",
    "    df_reverted = df_reverted.reindex(\n",
    "        pd.MultiIndex.from_product([revision_df.date.unique(), df_reverted.index.levels[1]], names=['date', 'user_kind']), fill_value=0)\n",
    "    df_reverts = df_reverts.reindex(\n",
    "        pd.MultiIndex.from_product([revision_df.date.unique(), df_reverts.index.levels[1]], names=['date', 'user_kind']), fill_value=0)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reverted.to_csv(f'{DATA_PATH}/processed_data/df_reverted.csv')\n",
    "df_reverts.to_csv(f'{DATA_PATH}/processed_data/df_reverts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily number of reverted edits or revert edits by page id\n",
    "\n",
    "Processes the data and returns two DataFrames called ```df_reverted_pid``` and ```df_reverts_pid```. The DataFrames are the same as above only that they are also grouped by page_id. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/..```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    # get reverts per day as well as reverted\n",
    "    df_reverted_pid = revision_df[revision_df['revision_is_identity_reverted'] == True].groupby(['date','page_id', 'user_kind'])['revision_is_identity_reverted'].size()\n",
    "    df_reverts_pid = revision_df[revision_df['revision_is_identity_revert'] == True].groupby(['date', 'page_id','user_kind'])['revision_is_identity_revert'].size()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Error: {str(e)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reverted_pid.to_csv(f'{DATA_PATH}/processed_data/df_reverted_by_pageid.csv')\n",
    "df_reverts_pid.to_csv(f'{DATA_PATH}/processed_data/df_reverts_by_pageid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get revert rate\n",
    "Revert Rate is defined as the ratio of reverts to all edits coming from non-bot accounts in a given time frame. It's a measure conflict amount editors. We calculate the revert rate on a daily basis in this case. The data is saved at ```/dlabdata1/turkish_wiki/processed_data/revert_rate.csv```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "edits = pd.read_csv(f'{DATA_PATH}/processed_data/edits.csv')\n",
    "reverts = pd.read_csv(f'{DATA_PATH}/processed_data/df_reverts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_non_bot_edits = edits[edits['user_kind'] != 'bot'].groupby(['date'])[['event_user_id']].sum()\n",
    "daily_identity_reverts = reverts.groupby(['date'])[['revision_is_identity_revert']].sum()\n",
    "revert_rate = pd.merge(daily_identity_reverts, daily_non_bot_edits, on = 'date', how = 'outer')\n",
    "revert_rate['revert_rate'] = revert_rate['revision_is_identity_revert']/revert_rate['event_user_id']\n",
    "revert_rate =revert_rate.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_rate['date'] = pd.to_datetime(revert_rate['date'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_rate = revert_rate.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_rate = revert_rate[['revert_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(revert_rate.index.min(), revert_rate.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_rate = revert_rate.reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_rate.to_csv(f'{DATA_PATH}/processed_data/revert_rate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
